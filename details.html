<p style="text-align:center"><strong><span style="font-size:26px">DETAILS</span></strong></p>

<hr />
<div style="padding-left: 100px; padding-right: 100px;">
  <h2><strong>What is the current weather forecasting model used by the meteorological agency?</strong></h2>

    <p>Modern numerical weather prediction (NWP) is a scientific method of forecasting future weather conditions using complex mathematical models on computers. It&#39;s the mainstream weather forecasting method adopted by meteorological departments around the world. Among them, the high-resolution integrated forecasting system (IFS) model from ECMWF has been one of the best NWP over the years.</p>

  <h2><strong>What are the benefits of implementing AI models?</strong></h2>

    <p>Artificial Intelligence (AI) is increasingly being used in weather prediction due to its ability to efficiently process massive amounts of data and recognize complex patterns within it. Unlike traditional NWP models which involve a time-consuming process of manually encoding physical laws into the model, AI can learn from past weather data to improve the accuracy of future forecasts. Furthermore, the speed at which AI models can process data enables them to provide real-time or near-real-time forecasts, significantly improving upon the time latency inherent in traditional models. In essence, AI offers a robust, fast, and data-driven approach to weather forecasting, significantly augmenting traditional methods with its predictive prowess and speed.</p>

    <h2><strong>What is FCN and how is it different from conventional models?</strong></h2>

    <p>FCN is an innovative weather prediction model rooted in AI. This model is the brainchild of researchers from NVIDIA, Lawrence Berkeley National Laboratory, the University of Michigan Ann Arbor, and Rice University. FourCastNet excels in forecasting high-resolution, rapid-timescale variables such as surface wind speed, precipitation, and atmospheric water vapor by discerning various patterns embedded in diverse meteorological data. This capability is crucial for strategic planning of wind energy resources and accurate prediction of extreme weather phenomena like tropical cyclones, extra-tropical cyclones, and atmospheric rivers. In terms of accuracy, FCN matches IFS and even outperforms that model when dealing with variables that encompass intricate microscale structures, such as precipitation. Remarkably, FCN can produce a week-long forecast in less than 2 seconds, a speed that is significantly faster than IFS. This rapidity enables FourCastNet to generate swift and economical large-ensemble forecasts with thousands of ensemble members, thereby enhancing the quality of probabilistic forecasting.</p>

<p><span style="font-size:22px"><span style="font-family:Arial,Helvetica,sans-serif"><strong>Understanding the Key Concepts and Architecture of FCN:</strong></span></span></p>

<p><span style="font-size:16px"><span style="font-family:Arial,Helvetica,sans-serif">AFNO&nbsp;</span></span><br />
<span style="font-size:14px"><span style="font-family:Arial,Helvetica,sans-serif">The Adaptive Fourier Neural Operator (AFNO) is a machine learning model used for learning patterns in high-dimensional data such as images or time-series data. It is based on the Fourier transform, which converts data into the frequency domain, allowing it to effectively learn global patterns in the data and efficiently handle high-resolution data. These characteristics are particularly useful in dealing with data that have complex patterns, such as in weather forecasting.</span></span></p>

<p><br />
<span style="font-size:16px"><span style="font-family:Arial,Helvetica,sans-serif">ViT&nbsp;</span></span><br />
<span style="font-size:14px"><span style="font-family:Arial,Helvetica,sans-serif">The Vision Transformer (ViT) is a machine learning model that applies transformer architecture, originally designed for natural language processing, to visual data. It treats an image as a sequence of patches or &#39;tokens&#39;, allowing it to capture both local and global patterns in the data. This approach has shown remarkable performance on a variety of computer vision tasks and scales well with increased model and dataset sizes.</span></span></p>

<p>&nbsp;</p>

<p><span style="font-size:16px"><span style="font-family:Arial,Helvetica,sans-serif">Token-mixing scheme</span></span><br />
<span style="font-size:14px"><span style="font-family:Arial,Helvetica,sans-serif">The token-mixing scheme is a part of ViT architecture that allows the model to capture interactions between different parts of an image. In the context of the FourCastNet model, a Fourier transform-based token-mixing scheme is used. This approach treats the mixing operation as a continuous global convolution, implemented efficiently in the Fourier domain with Fast Fourier Transforms (FFTs). This allows the model to handle high-resolution data efficiently and effectively.</span></span></p>

<p>&nbsp;</p>

<p><span style="font-size:16px"><span style="font-family:Arial,Helvetica,sans-serif">Autoregressive inference</span></span><br />
<span style="font-size:14px"><span style="font-family:Arial,Helvetica,sans-serif">Autoregressive inference is a method used in machine learning and statistics where predictions for future data points are made based on the values of previous data points. In the context of time series data, like weather forecasting, an autoregressive model would predict future weather conditions based on past weather data. The term &quot;auto&quot; refers to the model&#39;s use of its own previous outputs as inputs for future predictions. This approach is particularly useful for tasks that involve sequential data, where the order of data points is important.</span></span></p>

<p>&nbsp;</p>

<p><strong><span style="font-size:18px"><span style="font-family:Arial,Helvetica,sans-serif">Step-by-Step Breakdown of the FourCastNet (FCN) Architecture</span></span></strong></p>

<p>&nbsp;</p>

<p><strong><span style="font-size:18px"><span style="font-family:Arial,Helvetica,sans-serif"><img alt="" src="https://ifh.cc/g/THvjK3.jpg" style="height:612px; width:926px" /></span></span></strong></p>

<p>&nbsp;</p>

<p><span style="font-size:14px"><span style="font-family:Arial,Helvetica,sans-serif">Step 1.&nbsp; &nbsp; The input variables are inputted into a lat-lon 2D grid (720 * 1440) and divided into (h * w) patches. Each patch is small, typically 8 * 8, and is represented as a d-dimensional token.</span></span><br />
&nbsp;</p>

<p><span style="font-size:14px"><span style="font-family:Arial,Helvetica,sans-serif">Step 2.&nbsp;&nbsp; &nbsp;A sequence is assigned to these divided patches, and positional information is also given. This is referred to as patch embedding and positional embedding.</span></span></p>

<p style="text-align:justify"><br />
<span style="font-size:14px"><span style="font-family:Arial,Helvetica,sans-serif">Step 3.&nbsp;&nbsp; &nbsp;Each layer is given an input tensor of patches (X = R^(hwd)), through which spatial mixing is performed. This spatial mixing takes place in the Fourier domain.</span></span></p>

<p style="text-align:justify"><br />
<span style="font-size:14px"><span style="font-family:Arial,Helvetica,sans-serif">Step 4.&nbsp;&nbsp; &nbsp;In the Fourier domain, the 2D discrete Fourier transform (DFT) is used to transform the tokens. This is a part of the spatial mixing process.</span></span></p>

<p style="text-align:justify"><br />
<span style="font-size:14px"><span style="font-family:Arial,Helvetica,sans-serif">Step 5.&nbsp;&nbsp; &nbsp;In the Fourier domain, weights are assigned to the tokens, and soft-thresholding and shrinkage are performed for sparsity.</span></span></p>

<p style="text-align:justify"><br />
<span style="font-size:14px"><span style="font-family:Arial,Helvetica,sans-serif">Step 6.&nbsp;&nbsp; &nbsp;After performing the inverse Fourier transform in the patch domain, residuals are added to prevent loss of original information.</span></span><br />
&nbsp;</p>

<p style="text-align:justify"><br />
<strong><span style="font-size:20px"><span style="font-family:Arial,Helvetica,sans-serif">Input Data for training FCN</span></span></strong></p>

  <table align="center" border="2" style="width:500px">
      <thead>
          <tr>
              <th scope="col", style="text-align:center">Vertical Level</th>
              <th scope="col", style="text-align:center">Variables</th>
          </tr>
      </thead>
      <tbody>
          <tr>
              <td style="text-align:center">Surface</td>
              <td style="text-align:center">U<span style="font-size:13.3333px"><sub>10</sub>, </span>V<span style="font-size:13.3333px"><sub>10</sub>, </span>T<span style="font-size:13.3333px"><sub>2m</sub>, sp, mslp</span></td>
          </tr>
          <tr>
              <td style="text-align:center">1000hPa</td>
              <td style="text-align:center">U, V<span style="font-size:13.3333px">,&nbsp;</span>Z</td>
          </tr>
          <tr>
              <td style="text-align:center">850hPa</td>
              <td style="text-align:center">T, U, V, Z, RH</td>
          </tr>
          <tr>
              <td style="text-align:center">500hPa</td>
              <td style="text-align:center">T, U, V, Z, RH</td>
          </tr>
          <tr>
              <td style="text-align:center">50hPa</td>
              <td style="text-align:center">Z</td>
          </tr>
          <tr>
              <td style="text-align:center">Integrated</td>
              <td style="text-align:center">TCWV</td>
          </tr>
      </tbody>
  </table>

  <ol>
      <li>
      <p>Surface Level Variables:</p>

      <ul>
          <li>U10, V10: Eastward and northward wind components at 10 meters above ground.</li>
          <li>T2m: Temperature 2 meters above the ground.</li>
          <li>sp and mslp: Atmospheric pressure at the Earth&#39;s surface and sea level respectively, crucial for predicting weather patterns and storm paths.</li>
      </ul>
      </li>
      <li>
      <p>1000hPa, 850hPa, 500hPa and 50hPa&nbsp;Level Variables:</p>

      <ul>
          <li>U, V: Eastward and northward wind components at respective pressure levels, used for understanding wind patterns at different altitudes.</li>
          <li>T: Temperature at respective pressure levels, valuable for predicting weather patterns.</li>
          <li>Z: Geopotential height at respective pressure levels, a key parameter for predicting height of a pressure surface above mean sea level.</li>
          <li>RH: Relative humidity at the 850 hPa and 500 hPa levels, representing atmospheric moisture content.</li>
      </ul>
      </li>
      <li>
      <p>Integrated Variables:</p>

      <ul>
          <li>TCWV: Total column water vapor, crucial for predicting precipitation, as it represents the total amount of water vapor in a vertical column of atmosphere.</li>
      </ul>
      </li>
  </ol>

<p><span style="font-size:14px"><span style="font-family:Arial,Helvetica,sans-serif">The ECMWF reanalysis project, also known as ERA5, is a meteorological reanalysis project carried out by ECMWF. This project has generated reanalyses for several years, with the most recent product, ERA5, offering higher spatial resolution (31 km) and covering the period from 1979 to the present. The reanalysis makes use of various sources of meteorological observations, including radiosondes, balloons, aircraft, buoys, satellites, and scatterometers. The data is run through the ECMWF computer model at a 125 km resolution. The reanalysis was done to improve the accuracy of historical weather maps and aid in a more detailed analysis of various weather systems through a period that was lacking in computerized data.</span></span></p>

<p><span style="font-size:14px"><span style="font-family:Arial,Helvetica,sans-serif">The variables used in the FourCastNet model from the ERA5 dataset include surface pressure, two-meter temperature, total column water, and several others. These variables are specifically chosen to model important processes that influence low-level winds and precipitation.&nbsp;</span></span><span style="font-size:14px"><span style="font-family:Arial,Helvetica,sans-serif">Please refer to the table above for a detailed list of the variables used in FCN from the ERA5 dataset.The data is normalized by subtracting the mean and dividing by the standard deviation, calculated over the entire training period. The model is trained to predict the future state of these variables given their past states. The training is done using a sliding window approach, where the model is trained to predict the state of the variables at a future time step given their states at the current and past time steps. The model is trained using the Adam optimizer with a learning rate of 1e-4 and a batch size of 1. The training loss is the mean squared error between the model&#39;s predictions and the true future states of the variables. The model is trained for 200 epochs, and the model with the lowest validation loss is selected for evaluation.</span></span></p>

<p style="text-align:justify">&nbsp;</p>

<p style="text-align:justify">&nbsp;</p>
</div>
